---
published: true
title: 对话系统论文笔记六
category: Dialogue System
tags: 
  - DL
  - DS
  - paper reading
layout: post




---

2019.11.22 更新 Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders

2019.11.26 更新 Learning from Dialogue after Deployment: Feed Yourself, Chatbot!

# Generating Multiple Diverse Responses for Short-Text Conversation

AAAI 2019

## 总结

# Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders

ACL 2017

## 总结

这篇将CVAE引入了对话的seq2seq架构，具体做法是，context $c$ 和 response $x$ 通过 Recognition Network生成 $z$，context $c$ 单独通过 Prior Network生成 $z^{'}$，通过KL散度使这两者的分布尽量相同，从而得到了一个更好的编码器，并且我们能通过在 $z$ 的分布中采样，输入decoder中得到不同回复。

# Chat More: Deepening and Widening the Chatting Topic via A Deep Model

SIGIR 2018

## 总结

# Learning from Dialogue after Deployment: Feed Yourself, Chatbot!

ACL 2019

## 总结

算是别出心裁的一个工作，但是还有地方仍需可解释性。文章的motivation是：人类在学习如何对话时，不仅仅参考别人之间的对话，并且在自己和他人对话后接受对方的反馈，提升自身对话本领。所以，如果我们能在agent与human对话后，获取user对当前response的feedback，再通过feedback调整模型，是不是能够提高模型的性能呢？作者先用`PersonaChat`数据集训练好一个对话agent，再通过supervised learning人工标注sentiment label后训练一个`satisfaction predictor`，如果判断user满意agent的response，则将user的response作为新数据收集起来，如果判断user不满意agent的response,比如" What are you talking about?"，则通过提问题的方式获取user的feedback，将feedback作为新数据收集起来，新数据+旧数据重新训练，模型性能有了明显提升。有一点需要提的是，此model不管feedback的类型和内容如何，均按照一样的处理方式，作者相信feedback和context之间存在联系。这种暴力的直接将feedback丢进去model的方式肯定是有待商榷的，文章没能说服我。