---
published: true
title: 对话系统论文笔记四：主题
category: Dialogue System
tags: 
  - DL
  - DS
  - paper reading
layout: post


---

2019.11.15 更新 Target-Guided Open-Domain Conversation

2019.11.15 更新 Proactive Human-Machine Conversation with Explicit Conversation Goals

2019.11.15 更新 Proactive Knowledge-Goals Dialogue System Based on Pointer Network

2019.11.25 更新 Chat More If You Like: Dynamic Cue Words Planning to Flow Longer Conversations



# Target-Guided Open-Domain Conversation

ACL 2019

## 总结

这篇文章想要解决的问题是：在对话的过程中由一个随机的topic(文章里简单把key word当作topic)逐渐转到一个给定的topic (target)。如下图所示

![target-guied](https://github.com/Logos23333/Logos23333.github.io/blob/master/_posts/image/paper/target-guided.png?raw=true)

在对话开始时agent有一个target topic `e-books`,而user最开始聊的是`tired`，在对话过程中，topic逐渐转移成`e-books`。

文章的模型非常简单，整个模型分成三个部分：

- keyword predictor: 这个module用监督学习的方法预测下一句的key word

- keyword selection: 进一步在上一个module得到的candicates里选择一个key word，此key word与target的相似度需要比原来的高，这样可以保证key word最后一定会收敛到target (cosine similarity)

- reponse retrieval: 用检索式的方法选择一个与key word最相关的response



# Proactive Human-Machine Conversation with Explicit Conversation Goals

ACL 2019

## 总结

这篇文章定义的问题是，给定context $X$，dialogue goal $G$ = [$start, topic\_a, topic\_b$]，related knowledge $K$，生成能完成dialogue goal及包含相关知识并与上下文有关的response $Y$。针对这个新问题，文章提出了一个新的数据集，这个数据集的每一个dialogue都由一个leader和follower人工生成，leader负责引导topic，而follower只作response。文章还针对此问题提出了模型，将knowledge和 goal等隐式编码，再经过几层处理最后得到response。看了文章我最大的疑惑就是，为什么将 dialogue goal隐式编码就能够进行话题的转移呢？在它的model里，dialogue goal甚至是和knowleage等一起编码的，很不可解释。有没有这么一种可能，这个user goal完全没有作用，只是因为这个数据集足够好，实验的结果才比较好看？相对来说，我很不喜欢这篇论文，不客气的讲，完全是拿钱堆出来的论文，对于读者而言没有启发。

# Proactive Knowledge-Goals Dialogue System Based on Pointer Network

NLPCC 2019

## 总结

这篇文章应该是打了百度的比赛，然后把自己比赛的模型拿出来投稿，但是文章有很多错漏，前后逻辑也有不通顺之处，数学符号不规范，最重要的是它motivation有讲如何引导topic，但是在model部分完全就是把自己的model罗列出来，根本没有进行解释，也没有与motivation形成对应关系。

无语。

# Chat More If You Like: Dynamic Cue Words Planning to Flow Longer Conversations

## 总结

2018年11月就挂在arxiv上的工作。这个工作也是做topic motivation，但是并没有提出一个target topic，而是说在当前topic结束的时候如何转向一个更好的topic，这里有三个问题，一是如何判断当前topic该结束了，二是用什么指标来说明转移后的topic非常合适，三是用什么数据集做实验。但文章通篇没有提到当前topic的*结束标志*，用来评价response的指标也都还是那几个，没什么有用的信息。来讲一讲模型部分，整个模型就分成两个部分，如何选择cue word（其实也就是Keyword）,如何将cue word引入生成response，关于后者，文章采用了一般的做法，也就是seq2seq，将cue word的embedding隐式编码，关于前者，作者用了一个RL的框架用于选择更好的cue word，关于RL其实只需要看它的reward部分，模型用了两个指标来计算Reward，$effectiveness$和$relevance$，前者计算cue word跟当前utterance和生成utterance的cos相似度，后者计算生成的utterance和context的相关度。